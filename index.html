<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="content-type" content="application/xhtml+xml; charset=UTF-8" />
    <meta />
    <meta />
    <meta />
    <link rel="stylesheet" type="text/css" href="../../style/origo.css" media="all" />
    <meta name="author" content="Lei Li" />
    <title>DL</title>
  </head>
  <body>
    <h1 align="center">CS 190I Deep Learning (Winter 2023)<br />
    </h1>
    <h2>Course Description </h2>
    <p>Deep Learning has been driving the progress of AI in the past decade and has found versatile applications in many products and everyday life. 
      Examples include recommendation systems for online videos, automatic language translation, smart home assistants, creative art design, and autonomous driving vehicles.
      This course will introduce general principles, methods, network architectures, and applications of Deep Learning.   
      We cover neural network architectures including convolutional neural networks, recurrent neural networks,
      Transformer, and graph neural networks. We will cover techniques for
      designing loss, training, and inference methods. We focus on both the
      principles, analytical skills, and implementation practice. This course is
      suitable for undergraduate students and graduate students who wants to
      pursue career in AI or do research in deep learning. </p>
    <h2>Instructor</h2>
    <p><a href="https://www.cs.ucsb.edu/%7Eleili">Lei Li</a> 
      (Office Hour:  Monday 7-8pm, 2121 HFH, book a slot <a href="https://calendar.app.google/PtAXkmoYUGHsMd4s5">here</a>)
    </p>
    <h2>Teaching Assistant</h2>
    <ul>
      <li>Krushna Shah (Office Hour: Tuesday 2-3pm, Trailer 936)</li>
      <li>Zoey Song (Office Hour: Thursday 5-6pm, HH 2014) </li>
      <li>Danqing Wang (Office Hour: Wednesday 11-12am, HH 2014) </li>
    </ul>
    <h2>Time and Location</h2>
    <p> Monday and Wednesday, 2-3:15pm, CHEM 1171</p>
    <p> Recitation sessions: </p>
    <ul>
      <li>Friday 9-9:50am, PHELP 1444</li>
      <li>Friday 10-10:50am, PHELP 1440</li>
      <li>Friday 11-11:50am, PHELP 1440</li>
    </ul>
    <h2>Textbook</h2>
    <ul>
      <li>[D2L] Dive into Deep Learning, Aston Zhang, Zachary Lipton, Mu
        Li, Alexander Smola. available <a moz-do-not-send="true" href="https://d2l.ai/">online</a>.</li>
    </ul>
    The textbook below is a great resource for those hoping to brush up on the
    prerequisite mathematics background for this course.
    <ul>
      <li>Mathematics for Machine Learning, Marc Peter Deisenroth, A. Aldo
        Faisal, and Cheng Soon Ong. Free <a href="https://mml-book.github.io/">online</a>.<br />
        <br />
      </li>
    </ul>
    <h2>Prerequisites</h2>
    <p> Prerequisites: Students need to grasp knowledge in Linear algebra,
      Calculus, Probability and Statistics, basic data structure and algorithms, and significant
      experience in computer programming (python or C++).</p>
    <p>CS 130A, 130B, MATH 3B, MATH 6A, PSTAT 120A, 120B.<br />
    </p>
    <h2>Homework Submission &amp; Grading</h2>
    <ul>
      <li>Please submit your homework at gradescope.
      </li>
      <li>There are a total of three late days allowed for all assignments (combined). </li>
    </ul>
    <h2>Discussion Forum</h2>
    <p>We will use Ed platform. <a href="https://edstem.org/us/join/DEfrrn">sign up here</a>
    </p>
    <h2>Policy</h2>
    <p>Please read the following <a href="course_policy.html">Link</a>
      carefully!<br />
    </p>
    <h2>Syllabus</h2>
    <table width="100%" border="0">
      <tbody>
        <tr>
          <td>#<br />
          </td>
          <td>Date<br />
          </td>
          <td>Topic<br />
          </td>
          <td>Reading<br />
          </td>
          <td>Homework<br />
          </td>
        </tr>
        <tr>
          <td>1<br />
          </td>
          <td>1/9<br />
          </td>
          <td> <a href="01-intro.pdf">Introduction </a><br />
          </td>
          <td>Chap 1, 2 of D2L<br />
          </td>
          <td><a href="cs190I_dl23w_hw1.pdf">HW1 </a><br />
          </td>
        </tr>
        <tr>
          <td>2<br />
          </td>
          <td>1/11<br />
          </td>
          <td><a href="02-linear-model.pdf"> Linear Models, Vector Calculus </a><br />
          </td>
          <td>Chap 3 of D2LC<br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td><br />
          </td>
          <td>1/13</td>
          <td>Recitation: <a href="recitation_week1.pdf">recitation_week1</a></td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td><br />
          </td>
          <td>1/16</td>
          <td>holiday. no class</td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>        
        <tr>
          <td>3<br />
          </td>
          <td>1/18<br />
          </td>
          <td><a href="03-logistic-regression.pdf">Logistic Regression, Cross
              Entropy</a><br />
          </td>
          <td>Chap 4 of D2L<br />
          </td>
          <td>MP1 out<br />
          </td>
        </tr>
        <tr>
          <td><br />
          </td>
          <td>1/20</td>
          <td>Recitation: <a href="recitation_week2.pdf">recitation_week2</a></td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>        
        <tr>
          <td>4<br />
          </td>
          <td>1/23<br />
          </td>
          <td><a href="04-ffn.pdf">Feedforward Network, Empirical Risk
              Minimization, Gradient Descent</a><br />
          </td>
          <td>Chap 5 of D2L<br />
          </td>
          <td></td>
        </tr>
        <tr>
          <td>5<br />
          </td>
          <td>1/25<br />
          </td>
          <td><a href="05-learning_ffn.pdf">Learning FFN</a><br />
          </td>
          <td>Chap 5 of D2L<br />
          </td>
          <td>HW1 due, HW2 out<br />
          </td>
        </tr>
        <tr>
          <td><br />
          </td>
          <td>1/27</td>
          <td>Recitation:</td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td>6<br />
          </td>
          <td>1/30<br />
          </td>
          <td><a href="06-evaluation.pdf">Model Evaluation</a></td>
          <td>Chap 6 of D2L<br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td>7<br />
          </td>
          <td>2/1<br />
          </td>
          <td><a href="07-regularization.pdf"> Regularization and other training techniques </a> </td>
          <td>Chap 6 of D2L<br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td><br />
          </td>
          <td>2/3</td>
          <td>Recitation: <a href="recitation_week4.pdf">recitation_week4</a></td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>        
        <tr>
          <td>8<br />
          </td>
          <td>2/6<br />
          </td>
          <td><a href="08-cnn.pdf"> Convolutional Neural Networks</a> </td>
          <td>Chap 7 of D2L<br />
          </td>
          <td></td>
        </tr>
        <tr>
          <td>9<br />
          </td>
          <td>2/8<br />
          </td>
          <td><a href="08-cnn.pdf">  Convolutional Neural Networks  </a><br />
          </td>
          <td>Chap 7 of D2L<br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td><br />
          </td>
          <td>2/10</td>
          <td>Recitation:<a href="recitation_week5.pdf">recitation_week5</a></td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td>10<br />
          </td>
          <td>2/13<br />
          </td>
          <td><a href="09-resnet.pdf"> ResNet and other CNN variants  </a><br />
          </td>
          <td>Chap 8 of D2L<br />
          </td>
          <td>HW2 Due, HW3 out<br />
          </td>
        </tr>
        <tr>
          <td>11<br />
          </td>
          <td>2/15<br />
          </td>
          <td> <a href="10-optimization.pdf"> Optimization for ML </a><br />
          </td>
          <td>Chap 12 of D2L<br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td><br />
          </td>
          <td>2/17</td>
          <td>Recitation:</td>
          <td><br />
          </td>
          <td>MP1 Due, MP2 Out<br />
          </td>
        </tr>        
        <tr>
          <td><br />
          </td>
          <td>2/20<br />
          </td>
          <td>holiday. no class<br />
          </td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>        
        <tr>
          <td>12<br />
          </td>
          <td>2/22<br />
          </td>
          <td> <a href="11-detection.pdf"> Object Detection
            </a><br />
          </td>
          <td>Chap 14 of D2L<br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td><br />
          </td>
          <td>2/24</td>
          <td>Recitation:</td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>        
        <tr>
          <td>13<br />
          </td>
          <td>2/27<br />
          </td>
          <td> <a href="12-recurrent_neural_net.pdf"> Recurrent Neural Networks </a></td>
          <td>Chap 9 of D2L<br />
          </td>
          <td></td>
        </tr>
        <tr>
          <td>14<br />
          </td>
          <td>3/1<br />
          </td>
          <td><a href="13-seq2seq.pdf"> Sequence-to-sequence Models </a> </td>
          <td>Chap 10 of D2L<br />
          </td>
          <td>HW3 Due<br />
          </td>
        </tr>
        <tr>
          <td><br />
          </td>
          <td>3/5</td>
          <td>Recitation:</td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>        
        <tr>
          <td>15<br />
          </td>
          <td>3/6<br />
          </td>
          <td><a href="14-Transformer.pdf"> Transformer </a> </td>
          <td>Chap 11 of D2L<br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td>16<br />
          </td>
          <td>3/8<br />
          </td>
          <td><a href="15-pretraining.pdf"> NLP Pretraining </a> </td>
          <td><a href="http://arxiv.org/abs/1609.02907">GCN</a>, <a href="https://arxiv.org/pdf/1704.01212.pdf">MPNN</a><br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td><br />
          </td>
          <td>3/10</td>
          <td>Recitation:</td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>        
        <tr>
          <td>17<br />
          </td>
          <td>3/13<br />
          </td>
          <td><a href="16-GNN.pdf///17-VAE.pdf">Graph Neural Network Autoencoder and VAE </a> </td>
          <td> <a href="http://arxiv.org/abs/1312.6114">VAE</a>, <a href="https://aclanthology.org/K16-1002">Sentence VAE</a> <br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td>18<br />
          </td>
          <td>3/15<br />
          </td>
          <td><a href="18-GAN.pdf"> GAN </a></td>
          <td> Chap 18 of D2L<br />
          </td>
          <td>MP2 Due<br />
          </td>
        </tr>
        <tr>
          <td><br />
          </td>
          <td>3/17</td>
          <td>Recitation: Final Prep</td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>        
        <tr>
          <td><br />
          </td>
          <td>3/xx<br />
          </td>
          <td>Final Exam<br />
          </td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>
      </tbody>
    </table>
    <p><br />
    </p>
  </body>
</html>
