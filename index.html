<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.1 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
  <head>
    <meta http-equiv="content-type" content="application/xhtml+xml; charset=UTF-8" />
    <meta />
    <meta />
    <meta />
    <link rel="stylesheet" type="text/css" href="../../style/origo.css" media="all" />
    <meta name="author" content="Lei Li" />
    <title>MLDL</title>
  </head>
  <body>
    <h1 align="center">190I Deep Learning (Winter 2023)<br />
    </h1>
    <h2>Course Description </h2>
    <p>Deep Learning has been driving the progress of AI in the past decade and has found versatile applications in many products and everyday life. 
      Examples include recommendation systems for online videos, automatic language translation, smart home assistants, and autonomous driving vehicles.
      This course will introduce general principles, methods, network architectures, and applications of Deep Learning.   
      We cover neural network architectures including convolutional neural networks, recurrent neural networks,
      Transformer, and graph neural networks. We will cover techniques for
      designing loss, training, and inference methods. We focus on both the
      principles, analytical skills and implementation practice. This course is
      suitable for undergraduate students and graduate students who wants to
      pursue career in AI or do research in deep learning. </p>
    <h2>Instructor</h2>
    <p><a href="https://www.cs.ucsb.edu/%7Eleili">Lei Li</a> <br />
      Office Hour:  2121 HFH
    </p>
    <h2>Teaching Assistant</h2>
    <ul>
      <li> </li>
    </ul>
    <h2>Time and Location</h2>
    <p>  </p>
    <p> </p>
    <ul>
      <li></li>
    </ul>
    <h2>Textbook</h2>
    <ul>
      <li>[D2DL] Dive into Deep Learning, Aston Zhang, Zachary Lipton, Mu
        Li, Alexander Smola. available <a moz-do-not-send="true" href="https://d2l.ai/">online</a>.</li>
    </ul>
    The textbook below is a great resource for those hoping to brush up on the
    prerequisite mathematics background for this course.
    <ul>
      <li>Mathematics for Machine Learning, Marc Peter Deisenroth, A. Aldo
        Faisal, and Cheng Soon Ong. Free <a href="https://mml-book.github.io/">online</a>.<br />
        <br />
      </li>
    </ul>
    <h2>Prerequisites</h2>
    <p> Prerequisites: Students need to grasp knowledge in Linear algebra,
      Calculus, Probability and Statistics, basic data structure and algorithms, and significant
      experience in computer programming (python or C++).</p>
    <p>CS 130A, 130B, MATH 3B, MATH 6A, PSTAT 120A, 120B.<br />
    </p>
    <h2>Homework Submission &amp; Grading</h2>
    <ul>
      <li>Gradescope: Please singup 
      </li>
      <ul>
      </ul>
    </ul>
    <h2>Discussion Forum</h2>
    <p>We will use Ed platform. 
    </p>
    <h2>Policy</h2>
    <p>Please read the following <a href="course_policy.html">Link</a>
      carefully!<br />
    </p>
    <h2>Syllabus</h2>
    <table width="100%" border="0">
      <tbody>
        <tr>
          <td>#<br />
          </td>
          <td>Date<br />
          </td>
          <td>Topic<br />
          </td>
          <td>Reading<br />
          </td>
          <td>Homework<br />
          </td>
        </tr>
        <tr>
          <td>1<br />
          </td>
          <td>1/9<br />
          </td>
          <td> <a href="01-intro.pdf">Introduction </a><br />
          </td>
          <td>Chap 1 of GBC<br />
          </td>
          <td>HW1<br />
          </td>
        </tr>
        <tr>
          <td>2<br />
          </td>
          <td>1/11<br />
          </td>
          <td><a href="02-linear-model.pdf"> Linear Models, Vector Calculus </a><br />
          </td>
          <td>Chap 5 of GBC<br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td><br />
          </td>
          <td>1/13</td>
          <td>Recitation: <a href="week1_recitation1.pdf">slide1</a>, <a href="week1_recitation2.pdf">slides2</a></td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td><br />
          </td>
          <td>1/16</td>
          <td>holiday. no class</td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>        
        <tr>
          <td>3<br />
          </td>
          <td>1/18<br />
          </td>
          <td><a href="03-logistic-regression.pdf">Logistic Regression, Cross
              Entropy</a><br />
          </td>
          <td>Chap 5 of GBC<br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td><br />
          </td>
          <td>1/20</td>
          <td>Recitation: <a href="week2_recitation1.pdf">slide</a>, <a href="week2_recitation2.pdf">note</a></td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>        
        <tr>
          <td>4<br />
          </td>
          <td>1/23<br />
          </td>
          <td><a href="04-ffn.pdf">Feedforward Network, Empirical Risk
              Minimization, Gradient Descent</a><br />
          </td>
          <td>Chap 6 of GBC<br />
          </td>
          <td>HW1 due, HW2 out </td>
        </tr>
        <tr>
          <td>5<br />
          </td>
          <td>1/25<br />
          </td>
          <td><a href="05-backprop.pdf">Backpropagation and Autograd</a><br />
          </td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td><br />
          </td>
          <td>1/27</td>
          <td>Recitation:</td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td>6<br />
          </td>
          <td>1/30<br />
          </td>
          <td><a href="06-regularization.pdf"> Evaluation and Regularization </a></td>
          <td>Chap 7 of GBC<br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td>7<br />
          </td>
          <td>2/1<br />
          </td>
          <td><a href="07-cnn.pdf"> Convolutional Neural Network </a> </td>
          <td>Chap 9 of GBC<br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td>8<br />
          </td>
          <td>2/6<br />
          </td>
          <td><a href="08-resnet.pdf"> ResNet and other CNN variants </a> </td>
          <td><br />
          </td>
          <td>HW2 Due, HW3 out </td>
        </tr>
        <tr>
          <td>9<br />
          </td>
          <td>2/8<br />
          </td>
          <td><a href="09-learn_cnn.pdf"> Learning for CNN </a><br />
          </td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td>10<br />
          </td>
          <td>2/13<br />
          </td>
          <td><a href="10-optimization.pdf"> Optimization for ML </a><br />
          </td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td>11<br />
          </td>
          <td>2/15<br />
          </td>
          <td> <a href="11-detection.pdf"> Object Detection </a><br />
          </td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td><br />
          </td>
          <td>2/20<br />
          </td>
          <td>holiday. no class<br />
          </td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>        
        <tr>
          <td>12<br />
          </td>
          <td>2/22<br />
          </td>
          <td> <a href="12-recurrent_neural_net.pdf"> Recurrent Neural Networks
            </a><br />
          </td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td>13<br />
          </td>
          <td>2/27<br />
          </td>
          <td> <a href="13-seq2seq.pdf"> Sequence-to-sequence Models </a></td>
          <td><br />
          </td>
          <td>HW3 Due, HW4 out </td>
        </tr>
        <tr>
          <td>14<br />
          </td>
          <td>3/1<br />
          </td>
          <td><a href="14-Transformer.pdf"> Transformer </a> </td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td>15<br />
          </td>
          <td>3/6<br />
          </td>
          <td><a href="15-pretraining.pdf"> NLP Pretraining </a> </td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td>16<br />
          </td>
          <td>3/8<br />
          </td>
          <td><a href="16-GNN.pdf"> Graph Neural Network </a> </td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td>17<br />
          </td>
          <td>3/13<br />
          </td>
          <td><a href="17-VAE.pdf">Autoencoder and VAE </a> </td>
          <td><br />
          </td>
          <td>HW4 due on 3/8<br />
          </td>
        </tr>
        <tr>
          <td>18<br />
          </td>
          <td>3/15<br />
          </td>
          <td><a href="18-GAN.pdf"> GAN </a></td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>
        <tr>
          <td><br />
          </td>
          <td>3/xx 12pm<br />
          </td>
          <td>Final Exam<br />
          </td>
          <td><br />
          </td>
          <td><br />
          </td>
        </tr>
      </tbody>
    </table>
    <p><br />
    </p>
  </body>
</html>
