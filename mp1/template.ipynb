{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "683b997d",
   "metadata": {
    "_cell_guid": "de67fb5d-5551-42c6-bebc-f502ee4a3705",
    "_uuid": "5485e009-b325-446a-a9c4-49145cb479e9",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:39:57.080408Z",
     "iopub.status.busy": "2023-01-15T07:39:57.079906Z",
     "iopub.status.idle": "2023-01-15T07:39:59.316955Z",
     "shell.execute_reply": "2023-01-15T07:39:59.315960Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 2.249245,
     "end_time": "2023-01-15T07:39:59.319512",
     "exception": false,
     "start_time": "2023-01-15T07:39:57.070267",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "\n",
    "# set the random seed for reproduction \n",
    "SEED=190\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "# checking if GPU is available or not\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f44027",
   "metadata": {
    "_cell_guid": "e9ea228d-63f1-440d-ba84-8a0f5dfe861b",
    "_uuid": "8744196d-13ef-48f7-9503-e10d76e19d58",
    "papermill": {
     "duration": 0.006675,
     "end_time": "2023-01-15T07:39:59.333461",
     "exception": false,
     "start_time": "2023-01-15T07:39:59.326786",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Load CelebA from Kaggle public dataset\n",
    "\n",
    "Use the 'Add Data' on the right and search 'CelebFaces Attributes (CelebA) Dataset' [https://www.kaggle.com/datasets/jessicali9530/celeba-dataset](https://www.kaggle.com/datasets/jessicali9530/celeba-dataset).\n",
    "\n",
    "Click the 'plus' button to add this dataset to the input directory of the current workspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318972cc",
   "metadata": {
    "_cell_guid": "f6d511be-1a21-4f45-ad49-ca0df725769a",
    "_uuid": "ca9191de-d5cc-4895-99cd-20744a608cd1",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:39:59.355893Z",
     "iopub.status.busy": "2023-01-15T07:39:59.355287Z",
     "iopub.status.idle": "2023-01-15T07:39:59.361027Z",
     "shell.execute_reply": "2023-01-15T07:39:59.359847Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.025004,
     "end_time": "2023-01-15T07:39:59.366203",
     "exception": false,
     "start_time": "2023-01-15T07:39:59.341199",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# set directory \n",
    "main_folder = '../input/celeba-dataset/'\n",
    "images_folder = main_folder + 'img_align_celeba/img_align_celeba/'\n",
    "\n",
    "IMG_WIDTH = 178\n",
    "IMG_HEIGHT = 218"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59e05d4e",
   "metadata": {
    "_cell_guid": "1939b5dd-9af8-471a-ae70-ef55a3e33268",
    "_uuid": "62b6aa10-2d66-422d-84e1-371c42e4a868",
    "papermill": {
     "duration": 0.014136,
     "end_time": "2023-01-15T07:39:59.393635",
     "exception": false,
     "start_time": "2023-01-15T07:39:59.379499",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 1. CelebA Overview\n",
    "This section take a brief look at the CelebA dataset, including the image example and the dataset statistic. If you are familiar with this dataset and image operations, just skip it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea1d01f",
   "metadata": {
    "_cell_guid": "ab21c85b-2209-4023-b45e-0295bcc2b6e7",
    "_uuid": "e07c7181-6f45-4476-b70e-48696bfaa47f",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:39:59.416095Z",
     "iopub.status.busy": "2023-01-15T07:39:59.415669Z",
     "iopub.status.idle": "2023-01-15T07:39:59.610129Z",
     "shell.execute_reply": "2023-01-15T07:39:59.609124Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.208444,
     "end_time": "2023-01-15T07:39:59.612726",
     "exception": false,
     "start_time": "2023-01-15T07:39:59.404282",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the data set that include the attribute for each picture\n",
    "df_partition = pd.read_csv(main_folder + 'list_eval_partition.csv')\n",
    "\n",
    "# display counter by partition\n",
    "# 0 -> TRAINING\n",
    "# 1 -> VALIDATION\n",
    "# 2 -> TEST\n",
    "df_partition['partition'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbe2235",
   "metadata": {
    "_cell_guid": "f167c86f-7ab4-491f-b85f-4c074be9776e",
    "_uuid": "9ac6e806-132a-409f-ae5e-488657862348",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:39:59.630501Z",
     "iopub.status.busy": "2023-01-15T07:39:59.629035Z",
     "iopub.status.idle": "2023-01-15T07:40:00.552775Z",
     "shell.execute_reply": "2023-01-15T07:40:00.551731Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.933804,
     "end_time": "2023-01-15T07:40:00.554937",
     "exception": false,
     "start_time": "2023-01-15T07:39:59.621133",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import the data set that include the attribute for each picture\n",
    "df_attr = pd.read_csv(main_folder + 'list_attr_celeba.csv')\n",
    "df_attr.set_index('image_id', inplace=True)\n",
    "df_attr.replace(to_replace=-1, value=0, inplace=True) #replace -1 by 0\n",
    "df_attr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb26bfbd",
   "metadata": {
    "_cell_guid": "f90430b7-8751-4927-ae7e-0904263af3d7",
    "_uuid": "eb951d9e-7a37-4d23-ad71-4037156919f9",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:40:00.570494Z",
     "iopub.status.busy": "2023-01-15T07:40:00.569615Z",
     "iopub.status.idle": "2023-01-15T07:40:00.588420Z",
     "shell.execute_reply": "2023-01-15T07:40:00.587425Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.028706,
     "end_time": "2023-01-15T07:40:00.590639",
     "exception": false,
     "start_time": "2023-01-15T07:40:00.561933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_attr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc7c93bd",
   "metadata": {
    "_cell_guid": "ac24416e-705a-482c-a26f-c8d9a14a6c22",
    "_uuid": "b640f38f-0591-4b69-b57f-947ae8a4e9e1",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:40:00.606494Z",
     "iopub.status.busy": "2023-01-15T07:40:00.606222Z",
     "iopub.status.idle": "2023-01-15T07:40:00.612463Z",
     "shell.execute_reply": "2023-01-15T07:40:00.611506Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.01704,
     "end_time": "2023-01-15T07:40:00.615373",
     "exception": false,
     "start_time": "2023-01-15T07:40:00.598333",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of available attributes\n",
    "for i, j in enumerate(df_attr.columns):\n",
    "    print(i, j)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca2e8d9",
   "metadata": {
    "_cell_guid": "6bdedae9-9d26-4751-891c-ad12420d8e6e",
    "_uuid": "d47d0f5c-8d95-449c-b370-e2929b7081d0",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:40:00.631638Z",
     "iopub.status.busy": "2023-01-15T07:40:00.630654Z",
     "iopub.status.idle": "2023-01-15T07:40:05.284655Z",
     "shell.execute_reply": "2023-01-15T07:40:05.283705Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.664502,
     "end_time": "2023-01-15T07:40:05.287067",
     "exception": false,
     "start_time": "2023-01-15T07:40:00.622565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# plot picture and attributes\n",
    "from keras.preprocessing.image import load_img\n",
    "EXAMPLE_PIC = images_folder + '162151.jpg'\n",
    "img = load_img(EXAMPLE_PIC)\n",
    "plt.grid(False)\n",
    "plt.imshow(img)\n",
    "df_attr.loc[EXAMPLE_PIC.split('/')[-1]][['Smiling','Male','Young','Eyeglasses']] #some attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d9194b0",
   "metadata": {
    "_cell_guid": "be36e306-fe27-42c7-8047-a947368af1bd",
    "_uuid": "35722f05-2e98-41b4-9ec8-7ddb061d963f",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:40:05.304687Z",
     "iopub.status.busy": "2023-01-15T07:40:05.304396Z",
     "iopub.status.idle": "2023-01-15T07:40:05.495055Z",
     "shell.execute_reply": "2023-01-15T07:40:05.493508Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.20195,
     "end_time": "2023-01-15T07:40:05.497447",
     "exception": false,
     "start_time": "2023-01-15T07:40:05.295497",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# smiling\n",
    "plt.title('Smiling or non-Smiling')\n",
    "sns.countplot(y='Smiling', data=df_attr, color=\"c\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f6acb92",
   "metadata": {
    "_cell_guid": "ce3d448a-be31-41fd-be69-0788cc50de8e",
    "_uuid": "ad21f730-1fe6-4d3d-b436-3bd12e300151",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:40:05.515344Z",
     "iopub.status.busy": "2023-01-15T07:40:05.515061Z",
     "iopub.status.idle": "2023-01-15T07:40:05.589399Z",
     "shell.execute_reply": "2023-01-15T07:40:05.588306Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.085967,
     "end_time": "2023-01-15T07:40:05.591974",
     "exception": false,
     "start_time": "2023-01-15T07:40:05.506007",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# join the partition with the attributes\n",
    "df_partition.set_index('image_id', inplace=True)\n",
    "df_par_attr = df_partition.join(df_attr['Smiling'], how='inner')\n",
    "df_par_attr.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d65a037",
   "metadata": {
    "_cell_guid": "b739a78e-b5de-4625-bb56-49dcb4633f3b",
    "_uuid": "57b6c434-8a4e-4fae-b77f-4db7b8856be7",
    "papermill": {
     "duration": 0.008248,
     "end_time": "2023-01-15T07:40:05.608775",
     "exception": false,
     "start_time": "2023-01-15T07:40:05.600527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2.Dataset for Smiling\n",
    "This section load the data we use in this project. \n",
    "\n",
    "* **celeba_train.csv** the training dataset. The 'id' is the file name in celeba-dataset\n",
    "* **celeba_valid.csv** the validation dataset. The 'id' is the file name in celeba-dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ecd1de",
   "metadata": {
    "_cell_guid": "4dca4629-6533-4273-9c5f-2d866af5827f",
    "_uuid": "3a8aae95-6a0c-4d2e-b686-40aae12f1c89",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:40:05.627346Z",
     "iopub.status.busy": "2023-01-15T07:40:05.626466Z",
     "iopub.status.idle": "2023-01-15T07:40:05.669100Z",
     "shell.execute_reply": "2023-01-15T07:40:05.668166Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.054122,
     "end_time": "2023-01-15T07:40:05.671135",
     "exception": false,
     "start_time": "2023-01-15T07:40:05.617013",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "comp_path = '/kaggle/input/cs190-winter23-deep-learning-mp1'\n",
    "train_df = pd.read_csv(os.path.join(comp_path, 'celeba_train.csv'))\n",
    "valid_df = pd.read_csv(os.path.join(comp_path, 'celeba_valid.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad052ce6",
   "metadata": {
    "_cell_guid": "2174e7ec-b835-4204-a53a-3e246cc77637",
    "_uuid": "0f8a9ab1-c719-405c-a8c3-8b9b59cda85e",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:40:05.690609Z",
     "iopub.status.busy": "2023-01-15T07:40:05.689695Z",
     "iopub.status.idle": "2023-01-15T07:40:05.701833Z",
     "shell.execute_reply": "2023-01-15T07:40:05.701002Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.024054,
     "end_time": "2023-01-15T07:40:05.703855",
     "exception": false,
     "start_time": "2023-01-15T07:40:05.679801",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de062a8c",
   "metadata": {
    "_cell_guid": "8f4b18fc-ceb4-4c8b-b69b-97d97a029272",
    "_uuid": "bb770980-f776-48ee-be34-e3f88c948c12",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:40:05.722194Z",
     "iopub.status.busy": "2023-01-15T07:40:05.721918Z",
     "iopub.status.idle": "2023-01-15T07:40:05.733471Z",
     "shell.execute_reply": "2023-01-15T07:40:05.732355Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.023322,
     "end_time": "2023-01-15T07:40:05.735727",
     "exception": false,
     "start_time": "2023-01-15T07:40:05.712405",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data.dataset import Dataset\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "\n",
    "class CelebADataset(Dataset):\n",
    "    def __init__(self, img_path, imgs, labels, resize=None, inference=False):\n",
    "        \"\"\"\n",
    "            img_path: str, the directory of celeba dataset \n",
    "            imgs: List[str], the image file names\n",
    "            labels: List[int], the 0/1 label for each image\n",
    "            resize: None or int, whether downsample or upsample the image to certain size\n",
    "            inference: bool, True for the data without the label\n",
    "        \"\"\"\n",
    "        self.img_path = img_path\n",
    "        self.resize = resize\n",
    "        self.imgs = imgs\n",
    "        self.labels = labels\n",
    "        self.inference = inference\n",
    "        \n",
    "        # Center crop the alingned celeb dataset to 178x178 to include the face area \n",
    "        # and then downsample to 128x128 .\n",
    "        self.pre_process = transforms.Compose([\n",
    "                                            transforms.CenterCrop((178, 178)),\n",
    "                                            transforms.Resize((128,128)),\n",
    "                                            ])\n",
    "\n",
    "                          \n",
    "        # first transform the images to tensor format, then normalize the pixel values\n",
    "        self.totensor = transforms.Compose([\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                    ])\n",
    "        \n",
    "        if resize is not None:\n",
    "            self.resampling = transforms.Resize((resize, resize))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        image_path = os.path.join(self.img_path, self.imgs[index])\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img = self.pre_process(img)\n",
    "        img_tensor = self.totensor(img)\n",
    "        if self.resize is not None:\n",
    "            img_tensor = self.resampling(img_tensor)\n",
    "        if not self.inference:\n",
    "            label = self.labels[index]\n",
    "            return img_tensor, label\n",
    "        else:\n",
    "            return img_tensor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7986058",
   "metadata": {
    "_cell_guid": "14c97243-3565-4f88-8a3f-2766f7d88454",
    "_uuid": "3d49f044-408b-4fb3-a79d-8293f7d07665",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:40:05.754498Z",
     "iopub.status.busy": "2023-01-15T07:40:05.754223Z",
     "iopub.status.idle": "2023-01-15T07:40:05.761643Z",
     "shell.execute_reply": "2023-01-15T07:40:05.760785Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.018875,
     "end_time": "2023-01-15T07:40:05.763709",
     "exception": false,
     "start_time": "2023-01-15T07:40:05.744834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "TEST_BATCH_SIZE = 1000\n",
    "\n",
    "# create the dataset\n",
    "train_ds = CelebADataset(images_folder, train_df['id'], train_df['label'])\n",
    "valid_ds = CelebADataset(images_folder, valid_df['id'], valid_df['label'])\n",
    "\n",
    "# build the dataloader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_ds, batch_size=BATCH_SIZE, shuffle=True\n",
    ")\n",
    "valid_loader = torch.utils.data.DataLoader(\n",
    "    valid_ds, batch_size=TEST_BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d3c1b5",
   "metadata": {
    "_cell_guid": "349222ff-81d0-4a82-b7a3-89ce956dfe1e",
    "_uuid": "ca400797-02ed-4e20-9020-c0167fed5f17",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:40:05.782587Z",
     "iopub.status.busy": "2023-01-15T07:40:05.782317Z",
     "iopub.status.idle": "2023-01-15T07:40:05.803609Z",
     "shell.execute_reply": "2023-01-15T07:40:05.802605Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.033336,
     "end_time": "2023-01-15T07:40:05.805784",
     "exception": false,
     "start_time": "2023-01-15T07:40:05.772448",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_ds[0][0].size(), train_ds[0][1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cdebf69",
   "metadata": {
    "_cell_guid": "c0a1f5a5-8203-41a6-b57a-6a035bd373a0",
    "_uuid": "52466db4-fbe8-4c93-8177-bf0752cdddc8",
    "papermill": {
     "duration": 0.008708,
     "end_time": "2023-01-15T07:40:05.823090",
     "exception": false,
     "start_time": "2023-01-15T07:40:05.814382",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Define the training and validation loops\n",
    "\n",
    "In this section, we define the learning process, including the training loop and validation loop.  \n",
    "\n",
    "For each epoch:\n",
    "1. Calculate the loss and the gradient on the training set. Use optimizer to update the parameters. \n",
    "2. Calculate the loss and accuracy on the validation set. Save the model when we get a better loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd30efdd",
   "metadata": {
    "_cell_guid": "984f832a-226a-4da9-bf54-82bd43f461a1",
    "_uuid": "f7aeaee9-44f6-49e3-881f-12e4b6501167",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:40:05.841762Z",
     "iopub.status.busy": "2023-01-15T07:40:05.841491Z",
     "iopub.status.idle": "2023-01-15T07:40:05.858849Z",
     "shell.execute_reply": "2023-01-15T07:40:05.857856Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.029101,
     "end_time": "2023-01-15T07:40:05.860803",
     "exception": false,
     "start_time": "2023-01-15T07:40:05.831702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Trainer(object):\n",
    "    def __init__(self, model, criterion, optimizer, max_epoch):\n",
    "        \"\"\"\n",
    "            model: nn model\n",
    "            criterion: loss function\n",
    "            optimizer: optimizer\n",
    "            max_epoch: maximum training epoch\n",
    "        \"\"\"\n",
    "        self.model = model.to(device)\n",
    "        self.criterion = criterion.to(device)\n",
    "        self.optimizer = optimizer\n",
    "        self.max_epoch = max_epoch\n",
    "        \n",
    "    def run(self,train_loader, valid_loader):\n",
    "        \"\"\"\n",
    "            Main entry\n",
    "                train_loader: training dataset, each item is (img, label)\n",
    "                valid_loader: validation dataset, each item is (img, label)\n",
    "        \"\"\"\n",
    "        # calculate the inital loss and accu on validation set\n",
    "        valid_best_loss = self.validate(-1, valid_loader, best_loss=None)\n",
    "        for epoch in range(self.max_epoch):\n",
    "            self.train(epoch, train_loader)\n",
    "            # save the checkpoint with the lowest validation loss\n",
    "            valid_best_loss = self.validate(epoch, valid_loader, valid_best_loss)\n",
    "        \n",
    "    def train(self, epoch, loader):\n",
    "        \"\"\"\n",
    "            Single training loop\n",
    "                epoch: int, current epoch index\n",
    "                loader: training loader\n",
    "        \"\"\"\n",
    "        # switch to the evaluation mode, do not calculate the gradient\n",
    "        self.model.train()\n",
    "        running_loss, total, correct = 0.0, 0, 0\n",
    "        with tqdm(enumerate(loader, 0), mininterval=10) as tepoch:\n",
    "            for i, data in tepoch:\n",
    "                # get the inputs; data is a list of [inputs, labels]\n",
    "                # inputs: tensor, (batch_size, image_size, image_size)\n",
    "                # labels: tensor, (batch_size, 1)\n",
    "                inputs, labels = data\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                \n",
    "                ########################################################\n",
    "                # TODO: replace the outputs and loss and update optimizer\n",
    "                # 1. zero the parameter gradients\n",
    "                # 2. forward + backward\n",
    "                # 3. update the parameters\n",
    "                outputs = None\n",
    "                loss = None\n",
    "                ########################################################\n",
    "                \n",
    "                # calculate the metric\n",
    "                match, number = self.cal_metric(outputs.data, labels)\n",
    "                \n",
    "                # gather statistics\n",
    "                total += number\n",
    "                correct += match\n",
    "                running_loss += loss.item()\n",
    "                tepoch.set_postfix(loss=loss.item(), accuracy=100. * correct / total)\n",
    "\n",
    "        running_loss /= len(loader)\n",
    "\n",
    "        print('Training | Epoch: {}| Loss: {:.3f} | Accuracy on train images: {:.1f}'.format \\\n",
    "              (epoch+1, running_loss, 100 * correct / total))\n",
    "        \n",
    "    def validate(self, epoch, loader, best_loss=None):\n",
    "        \"\"\"\n",
    "            Single evaluation loop\n",
    "                epoch: int, current epoch index\n",
    "                loader: validation loader\n",
    "                best_loss: float, current best loss\n",
    "        \"\"\"\n",
    "        # switch to the evaluation mode, do not need to calculate the gradient\n",
    "        self.model.eval()\n",
    "        running_loss, total, correct = 0.0, 0, 0\n",
    "        for i, data in tqdm(enumerate(loader)):\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            ########################################################\n",
    "            # TODO: replace the outputs and loss  \n",
    "            outputs = None\n",
    "            loss = None\n",
    "            ########################################################\n",
    "\n",
    "            # calculate the metric\n",
    "            match, number = self.cal_metric(outputs.data, labels)\n",
    "            \n",
    "            # gather statistics\n",
    "            total += number\n",
    "            correct += match\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        running_loss /= len(loader)\n",
    "\n",
    "        if best_loss is None or running_loss < best_loss:\n",
    "            # if a better loss appears, save the checkpoint\n",
    "            save_file = 'best_epoch{}_loss{:.2f}_accu{:.2f}.pt'.format(epoch+1, running_loss, 100 * correct / total)\n",
    "            print('Save to file: ', save_file)\n",
    "            torch.save(self.model, save_file)\n",
    "            \n",
    "            # overwrite the best_checkpoint.pt file\n",
    "            torch.save(self.model, 'best_checkpoint.pt')\n",
    "            \n",
    "            best_loss = running_loss\n",
    "\n",
    "        print('Validation | Epoch: {}| Loss: {:.3f} | Accuracy on val images: {:.1f}'.format \\\n",
    "              (epoch+1, running_loss,100 * correct / total))\n",
    "\n",
    "        return best_loss\n",
    "\n",
    "                \n",
    "    def cal_metric(self, outputs, labels):\n",
    "        \"\"\"\n",
    "            Calculate the accuracy\n",
    "                outputs: tensor (batch_size, number_class), the output of the model\n",
    "                labels: tensor (batch_size, 1), the ground truth\n",
    "        \"\"\"\n",
    "        # compare predictions to ground truth\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        number = labels.size(0)\n",
    "        correct = (predicted == labels).sum().item()\n",
    "        return correct, number"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b7befc",
   "metadata": {
    "_cell_guid": "71085132-e8a8-40d1-8439-b73ec2aab3c8",
    "_uuid": "aa6ba21d-92ab-4fb6-9428-26b6b201e55f",
    "papermill": {
     "duration": 0.008268,
     "end_time": "2023-01-15T07:40:05.877636",
     "exception": false,
     "start_time": "2023-01-15T07:40:05.869368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 4. Define the Model Structure\n",
    "\n",
    "Here we define a simple baseline model MLP for demonstration. There are many possible improvements on the modeling side including adding more layers, increasing hidden size, and using other activation functions.\n",
    "\n",
    "We also provice a [LeNet](https://en.wikipedia.org/wiki/LeNet) for a better performance. However, we leave some TODO for you to complete.\n",
    "\n",
    "The original LeNet is designed for image size with 28\\*28. However, the image in celeba (after pre-procession) is 128\\*128. Therefore, we change the hyperparameters of the architecture. Try to figure out which layers will be affected by the different image size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb0ffb0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(nn.Module):\n",
    "    \"\"\"\n",
    "        Multilayer perceptron network\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Linear(3*128*128, 2)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.layers(x)\n",
    "        # F.log_softmax returns the log probabilities of each class\n",
    "        # of shape (num_samples, num_classes)\n",
    "        return F.log_softmax(x, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65ab75f",
   "metadata": {
    "_cell_guid": "b29a2300-fd48-46f7-91d9-987c1f669140",
    "_uuid": "f8dd6d28-80d5-4ee4-8984-5dbd62700db0",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:40:05.896335Z",
     "iopub.status.busy": "2023-01-15T07:40:05.895588Z",
     "iopub.status.idle": "2023-01-15T07:40:05.903544Z",
     "shell.execute_reply": "2023-01-15T07:40:05.902615Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.019507,
     "end_time": "2023-01-15T07:40:05.905652",
     "exception": false,
     "start_time": "2023-01-15T07:40:05.886145",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LeNet(nn.Module):\n",
    "    \"\"\"\n",
    "        LeNet architecture\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 3 input image channel, 6 output channels, 5x5 square convolution\n",
    "        self.conv1 = torch.nn.Conv2d(3, 6, kernel_size = 5)\n",
    "        self.conv2 = torch.nn.Conv2d(6, 16, kernel_size = 5)\n",
    "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
    "        \n",
    "        ########################################################\n",
    "        # TODO: replace the input_size\n",
    "        # figure out the input dimension of the first linear layer\n",
    "        self.fc1 = torch.nn.Linear(input_size, 120)  \n",
    "        ########################################################\n",
    "        \n",
    "        self.fc2 = torch.nn.Linear(120, 84)\n",
    "        self.fc3 = torch.nn.Linear(84, 2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        ########################################################\n",
    "        # TODO: organize the forward pass\n",
    "        # Hint: \n",
    "        #     1. check the LeNet link above if you are not familiar with it\n",
    "        #     2. do not forget the activation function F.relu() \n",
    "        #     3. you may want to use torch.flatten() before the full connection layer\n",
    "        #     4. be careful with the dimension\n",
    "        ########################################################\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4c5fd11",
   "metadata": {
    "_cell_guid": "9edcb20e-076b-413c-a207-8bc2023b41a2",
    "_uuid": "49aa3242-e09f-43b3-9aec-bff2851613df",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:40:05.923698Z",
     "iopub.status.busy": "2023-01-15T07:40:05.923435Z",
     "iopub.status.idle": "2023-01-15T07:40:05.946458Z",
     "shell.execute_reply": "2023-01-15T07:40:05.944586Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.034785,
     "end_time": "2023-01-15T07:40:05.948942",
     "exception": false,
     "start_time": "2023-01-15T07:40:05.914157",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Here we use the MLP model as the baseline. You can change it to whatever model you like\n",
    "model = MLP()\n",
    "print(model)\n",
    "print('Model Parameters ', sum(p.numel() for p in model.parameters()))\n",
    "print('Trainable Parameters ', sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5d5098",
   "metadata": {
    "_cell_guid": "2af67abb-4a34-40b7-b6c1-a7856287c730",
    "_uuid": "ebe57617-2ada-4f6e-a3ce-aa028dfc4e5b",
    "papermill": {
     "duration": 0.008387,
     "end_time": "2023-01-15T07:40:05.966411",
     "exception": false,
     "start_time": "2023-01-15T07:40:05.958024",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 5. Training\n",
    "\n",
    "Finally, we define the model architecture, criterion (loss function) and optimizer to start our training process. The best checkpoint will be saved to **'best_checkpoint.pt'** under the **'/kaggle/working'** directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b825573e",
   "metadata": {
    "_cell_guid": "f972cdb4-3299-4551-845c-752c0154aefc",
    "_uuid": "e9d808c0-8557-402e-b52a-dc5b2fd5ec40",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:40:05.985191Z",
     "iopub.status.busy": "2023-01-15T07:40:05.984433Z",
     "iopub.status.idle": "2023-01-15T07:40:10.267019Z",
     "shell.execute_reply": "2023-01-15T07:40:10.266025Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 4.294359,
     "end_time": "2023-01-15T07:40:10.269422",
     "exception": false,
     "start_time": "2023-01-15T07:40:05.975063",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "NUM_EPOCH = 20\n",
    "LEARNING_RATE = 0.001\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=LEARNING_RATE, momentum=0.9)\n",
    "trainer = Trainer(model, criterion, optimizer, max_epoch=NUM_EPOCH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96b9a729",
   "metadata": {
    "_cell_guid": "ccf90c65-f623-4643-add3-2d361d56af1e",
    "_uuid": "277b40fe-917d-4186-b216-f71f7e0088af",
    "execution": {
     "iopub.execute_input": "2023-01-15T07:40:10.289240Z",
     "iopub.status.busy": "2023-01-15T07:40:10.288321Z",
     "iopub.status.idle": "2023-01-15T08:34:10.870835Z",
     "shell.execute_reply": "2023-01-15T08:34:10.869376Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 3240.594506,
     "end_time": "2023-01-15T08:34:10.872869",
     "exception": false,
     "start_time": "2023-01-15T07:40:10.278363",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer.run(train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3316d45d",
   "metadata": {
    "_cell_guid": "d4ace419-2304-48f2-9142-273ff67bf100",
    "_uuid": "9a1dc195-9372-4e55-81d4-74e2859a7712",
    "papermill": {
     "duration": 0.84692,
     "end_time": "2023-01-15T08:34:12.573425",
     "exception": false,
     "start_time": "2023-01-15T08:34:11.726505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 6. Predict and Submit\n",
    "\n",
    "When we get the best checkpoint, we can use it to predict the attribute of the images in the test set. In this section, we define a TestDataset. It is similar with the CelebADataset except the loading process. Finally, save the prediction to the **submission.csv** and submit the competition.\n",
    "\n",
    "* **test_img.pt** The test set. It includes 2000 examples, and each example is open image object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71de4f3e",
   "metadata": {
    "_cell_guid": "2c8ea449-fa90-4db7-844f-931423c45d50",
    "_uuid": "aec357e6-16d4-45f9-9e62-1c9fb65f6f6a",
    "execution": {
     "iopub.execute_input": "2023-01-15T08:34:14.216812Z",
     "iopub.status.busy": "2023-01-15T08:34:14.216452Z",
     "iopub.status.idle": "2023-01-15T08:34:14.225774Z",
     "shell.execute_reply": "2023-01-15T08:34:14.224859Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.857952,
     "end_time": "2023-01-15T08:34:14.227729",
     "exception": false,
     "start_time": "2023-01-15T08:34:13.369777",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class TestDataset(Dataset):\n",
    "    def __init__(self, imgs, resize=None):\n",
    "        \"\"\"\n",
    "            Similar with CelebADataset \n",
    "                imgs: open images\n",
    "                resize: None or int, whether downsample or upsample the image to certain size\n",
    "        \"\"\"\n",
    "        self.imgs = imgs\n",
    "        self.resize = resize\n",
    "        \n",
    "        # Center crop the alingned dataset to 178x178 to include the face area \n",
    "        # and then downsample to 128x128 .\n",
    "        self.pre_process = transforms.Compose([\n",
    "                                            transforms.CenterCrop((178, 178)),\n",
    "                                            transforms.Resize((128,128)),\n",
    "                                            ])\n",
    "\n",
    "                          \n",
    "        # first transform the images to tensor format, then normalize the pixel values\n",
    "        self.totensor = transforms.Compose([\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                                    ])\n",
    "        \n",
    "        if resize is not None:\n",
    "            self.resampling = transforms.Resize((resize, resize))\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        img = self.imgs[index]\n",
    "        img = self.pre_process(img)\n",
    "        img_tensor = self.totensor(img)\n",
    "        if self.resize is not None:\n",
    "            img_tensor = self.resampling(img_tensor)\n",
    "        return img_tensor\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da970321",
   "metadata": {
    "_cell_guid": "7adc5aaa-1cad-4b8b-a1d6-0bd0be065f49",
    "_uuid": "5d3a8675-f5ee-4984-99fa-1c122077a9b3",
    "execution": {
     "iopub.execute_input": "2023-01-15T08:34:15.869989Z",
     "iopub.status.busy": "2023-01-15T08:34:15.869009Z",
     "iopub.status.idle": "2023-01-15T08:34:15.877211Z",
     "shell.execute_reply": "2023-01-15T08:34:15.876303Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.858555,
     "end_time": "2023-01-15T08:34:15.879295",
     "exception": false,
     "start_time": "2023-01-15T08:34:15.020740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "TEST_BATCH_SIZE=1000\n",
    "\n",
    "def predict(model_path, test_file):\n",
    "    \"\"\"\n",
    "        Load the model and use it to predict test file \n",
    "    \"\"\"\n",
    "    test_data = torch.load(test_file)\n",
    "    test_dataset = TestDataset(test_data)\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "                    test_dataset, batch_size=TEST_BATCH_SIZE\n",
    "                )\n",
    "    \n",
    "    model = torch.load(model_path)\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        # labels are not available for the actual test set\n",
    "        for feature in tqdm(test_loader):\n",
    "            # calculate outputs by running images through the network\n",
    "            outputs = model(feature.to(device))\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            preds.extend(predicted.tolist())\n",
    "\n",
    "    return preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d269a162",
   "metadata": {
    "_cell_guid": "97af0b68-5bf7-4f5e-8bd7-1e6262e34257",
    "_uuid": "63cc2f38-6953-44c7-8001-33963c3c2cb0",
    "execution": {
     "iopub.execute_input": "2023-01-15T08:34:18.342310Z",
     "iopub.status.busy": "2023-01-15T08:34:18.341912Z",
     "iopub.status.idle": "2023-01-15T08:34:24.254463Z",
     "shell.execute_reply": "2023-01-15T08:34:24.253190Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 7.331534,
     "end_time": "2023-01-15T08:34:24.258461",
     "exception": false,
     "start_time": "2023-01-15T08:34:16.926927",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"best_checkpoint.pt\"\n",
    "test_file = \"/kaggle/input/cs190-winter23-deep-learning-mp1/test_img.pt\"\n",
    "preds = predict(model_path,test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78357b86",
   "metadata": {
    "_cell_guid": "f37edbf1-0c0c-4b3d-8b92-5811e803fd78",
    "_uuid": "1d3acdd7-140e-46d0-87e6-e20677163b29",
    "execution": {
     "iopub.execute_input": "2023-01-15T08:34:26.062764Z",
     "iopub.status.busy": "2023-01-15T08:34:26.061558Z",
     "iopub.status.idle": "2023-01-15T08:34:26.073474Z",
     "shell.execute_reply": "2023-01-15T08:34:26.072549Z"
    },
    "jupyter": {
     "outputs_hidden": false
    },
    "papermill": {
     "duration": 0.878378,
     "end_time": "2023-01-15T08:34:26.075667",
     "exception": false,
     "start_time": "2023-01-15T08:34:25.197289",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'id': list(range(len(preds))),'label': preds})\n",
    "df.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3280.312086,
   "end_time": "2023-01-15T08:34:30.016564",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-01-15T07:39:49.704478",
   "version": "2.3.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
